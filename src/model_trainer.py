"""
ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã¾ã§ã®è¨“ç·´ãƒ»è©•ä¾¡ã‚’è¡Œã†
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from interpret.glassbox import ExplainableBoostingClassifier
import joblib
from typing import Dict, List, Tuple, Any, Optional
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import time  # å®Ÿè¡Œæ™‚é–“æ¸¬å®šç”¨
warnings.filterwarnings('ignore')

class HealthLevelClassifier:
    """æ©‹æ¢å¥å…¨åº¦ãƒ¬ãƒ™ãƒ«åˆ†é¡å™¨"""
    
    def __init__(self, random_state: int = 42):
        self.random_state = random_state
        self.models = {}
        self.best_model = None
        self.feature_names = []
        self.label_mapping = {'â… ': 1, 'â…¡': 2, 'Repair-requirement': 3}
        self.reverse_label_mapping = {1: 'â… ', 2: 'â…¡', 3: 'Repair-requirement'}
        
    def prepare_data(self, X: np.ndarray, y: np.ndarray, 
                    test_size: float = 0.3, val_size: float = 0.5) -> Dict[str, np.ndarray]:
        """ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ï¼ˆTrain/Validation/Testï¼‰"""
        
        # ã‚¯ãƒ©ã‚¹æ•°ã®ç¢ºèªï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã‚¯ãƒ©ã‚¹ã‚’é™¤å¤–ã™ã‚‹ã‹ç¢ºèªï¼‰
        unique, counts = np.unique(y, return_counts=True)
        min_samples = counts.min()
        
        print(f"æœ€å°ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {min_samples}")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒæ¥µç«¯ã«å°‘ãªã„ã‚¯ãƒ©ã‚¹ï¼ˆ2æœªæº€ï¼‰ãŒã‚ã‚‹å ´åˆã¯å˜ç´”åˆ†å‰²
        if min_samples < 2:
            print("è­¦å‘Š: ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒæ¥µç«¯ã«å°‘ãªã„ã‚¯ãƒ©ã‚¹ãŒã‚ã‚‹ãŸã‚ã€å˜ç´”åˆ†å‰²ã‚’ä½¿ç”¨ã—ã¾ã™")
            
            # ã¾ãšTrain+Validationã¨Testã«åˆ†å‰²
            X_temp, X_test, y_temp, y_test = train_test_split(
                X, y, test_size=test_size, random_state=self.random_state
            )
            
            # Train+Validationã‚’Trainã¨Validationã«åˆ†å‰²
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size, random_state=self.random_state
            )
        else:
            # ã¾ãšTrain+Validationã¨Testã«åˆ†å‰²
            X_temp, X_test, y_temp, y_test = train_test_split(
                X, y, test_size=test_size, random_state=self.random_state, 
                stratify=y
            )
            
            # Train+Validationã‚’Trainã¨Validationã«åˆ†å‰²
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size, random_state=self.random_state,
                stratify=y_temp
            )
        
        return {
            'X_train': X_train, 'X_val': X_val, 'X_test': X_test,
            'y_train': y_train, 'y_val': y_val, 'y_test': y_test
        }
    
    def create_baseline_model(self) -> LogisticRegression:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰ã®ä½œæˆ"""
        return LogisticRegression(
            random_state=self.random_state,
            max_iter=1000,
            class_weight='balanced'
        )
    
    def create_lightgbm_model(self) -> lgb.LGBMClassifier:
        """LightGBMãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"""
        return lgb.LGBMClassifier(
            random_state=self.random_state,
            class_weight='balanced',
            n_estimators=100,
            learning_rate=0.1,
            max_depth=6,
            num_leaves=31,
            min_child_samples=20,
            subsample=0.8,
            colsample_bytree=0.8,
            objective='multiclass',
            verbose=-1
        )
    
    def create_xgboost_model(self) -> xgb.XGBClassifier:
        """XGBoostãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œå¼·åŒ–ç‰ˆï¼‰"""
        return xgb.XGBClassifier(
            random_state=self.random_state,
            n_estimators=200,
            learning_rate=0.05,
            max_depth=8,
            min_child_weight=3,
            subsample=0.8,
            colsample_bytree=0.8,
            scale_pos_weight=3,  # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œ
            objective='multi:softprob',
            eval_metric='mlogloss',
            verbosity=0,
            reg_alpha=0.1,
            reg_lambda=0.1
        )
    
    def create_catboost_model(self) -> cb.CatBoostClassifier:
        """CatBoostãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œï¼‰"""
        return cb.CatBoostClassifier(
            random_state=self.random_state,
            iterations=200,
            learning_rate=0.05,
            depth=8,
            l2_leaf_reg=3,
            bootstrap_type='Bernoulli',
            subsample=0.8,
            class_weights=[1, 1, 3],  # Repair-requirementã‚¯ãƒ©ã‚¹ã®é‡ã¿å¢—åŠ 
            verbose=False,
            loss_function='MultiClass',
            eval_metric='MultiClass'
        )
    
    def create_ebm_model(self) -> ExplainableBoostingClassifier:
        """Explainable Boosting Machineï¼ˆEBMï¼‰ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
        é«˜é€ŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 16ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ã€è¨ˆç®—é‡å‰Šæ¸›è¨­å®š
        """
        return ExplainableBoostingClassifier(
            random_state=self.random_state,
            # ä¸¦åˆ—å‡¦ç†è¨­å®š
            n_jobs=16,  # 16ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼
            # é«˜é€ŸåŒ–ã®ãŸã‚ã®è¨ˆç®—é‡å‰Šæ¸›
            max_bins=128,  # 256â†’128ã«å‰Šæ¸›ï¼ˆ2å€é«˜é€ŸåŒ–ï¼‰
            max_interaction_bins=16,  # 32â†’16ã«å‰Šæ¸›ï¼ˆ2å€é«˜é€ŸåŒ–ï¼‰
            interactions=5,  # 10â†’5ã«å‰Šæ¸›ï¼ˆ2å€é«˜é€ŸåŒ–ï¼‰
            outer_bags=4,  # 8â†’4ã«å‰Šæ¸›ï¼ˆ2å€é«˜é€ŸåŒ–ï¼‰
            inner_bags=0,  # å†…éƒ¨ãƒãƒƒã‚°ç„¡åŠ¹ã§ã•ã‚‰ã«é«˜é€ŸåŒ–
            # å­¦ç¿’åŠ¹ç‡åŒ–
            learning_rate=0.02,  # å­¦ç¿’ç‡å‘ä¸Šã§æ—©æœŸåæŸ
            validation_size=0.1,  # æ¤œè¨¼ã‚µã‚¤ã‚ºå‰Šæ¸›
            early_stopping_rounds=30,  # æ—©æœŸåœæ­¢ã‚’ç©æ¥µçš„ã«
            early_stopping_tolerance=1e-3,  # åæŸåˆ¤å®šã‚’ç·©ã‚ã‚‹
            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
            max_rounds=500,  # æœ€å¤§ãƒ©ã‚¦ãƒ³ãƒ‰æ•°åˆ¶é™
        )
    
    def create_random_forest_model(self) -> RandomForestClassifier:
        """Random Forestãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ï¼‰"""
        return RandomForestClassifier(
            random_state=self.random_state,
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced',
            n_jobs=16  # 16ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼
        )
    
    def create_ensemble_model(self) -> VotingClassifier:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆä»£æ›¿ãƒ¢ãƒ‡ãƒ«å«ã‚€ï¼‰"""
        base_models = [
            ('lr', self.create_baseline_model()),
            ('lgb', self.create_lightgbm_model()),
            ('catboost', self.create_catboost_model()),
            ('xgb', self.create_xgboost_model()),
            ('rf', self.create_random_forest_model())
        ]
        
        return VotingClassifier(
            estimators=base_models,
            voting='soft'
        )
    
    def train_single_model(self, model, X_train: np.ndarray, y_train: np.ndarray,
                          X_val: np.ndarray, y_val: np.ndarray, model_name: str) -> Dict[str, Any]:
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡ï¼ˆå®Ÿè¡Œæ™‚é–“æ¸¬å®šä»˜ãï¼‰"""
        
        print(f"\nTraining {model_name}...")
        start_time = time.time()
        
        # XGBoostã®ãŸã‚ã«ãƒ©ãƒ™ãƒ«ã‚’0ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›
        if 'XGBoost' in model_name or 'xgb' in str(type(model)).lower():
            y_train_encoded = y_train - 1  # 1,2,3 -> 0,1,2
            y_val_encoded = y_val - 1
        else:
            y_train_encoded = y_train
            y_val_encoded = y_val
        
        # è¨“ç·´
        model.fit(X_train, y_train_encoded)
        training_time = time.time() - start_time
        
        # äºˆæ¸¬
        y_train_pred = model.predict(X_train)
        y_val_pred = model.predict(X_val)
        
        # XGBoostã®å ´åˆã¯å…ƒã®ãƒ©ãƒ™ãƒ«ã«æˆ»ã™
        if 'XGBoost' in model_name or 'xgb' in str(type(model)).lower():
            y_train_pred = y_train_pred + 1
            y_val_pred = y_val_pred + 1
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
        results = {
            'model': model,
            'model_name': model_name,
            'training_time': training_time,
            'train_accuracy': accuracy_score(y_train, y_train_pred),
            'val_accuracy': accuracy_score(y_val, y_val_pred),
            'train_f1_macro': f1_score(y_train, y_train_pred, average='macro'),
            'val_f1_macro': f1_score(y_val, y_val_pred, average='macro'),
            'train_f1_weighted': f1_score(y_train, y_train_pred, average='weighted'),
            'val_f1_weighted': f1_score(y_val, y_val_pred, average='weighted'),
            'classification_report': classification_report(y_val, y_val_pred),
            'confusion_matrix': confusion_matrix(y_val, y_val_pred)
        }
        
        print(f"Training completed in {training_time:.2f} seconds")
        
        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚åŒæ§˜ã«ãƒ©ãƒ™ãƒ«èª¿æ•´ï¼ˆä¸¦åˆ—å‡¦ç†æœ‰åŠ¹åŒ–ï¼‰
        try:
            if 'XGBoost' in model_name or 'xgb' in str(type(model)).lower():
                cv_scores = cross_val_score(model, X_train, y_train_encoded, cv=5, scoring='f1_macro', n_jobs=16)
            else:
                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=16)
            results['cv_f1_macro_mean'] = cv_scores.mean()
            results['cv_f1_macro_std'] = cv_scores.std()
        except Exception as e:
            print(f"CVè©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            results['cv_f1_macro_mean'] = 0.0
            results['cv_f1_macro_std'] = 0.0
        
        print(f"Validation Accuracy: {results['val_accuracy']:.4f}")
        print(f"Validation F1 (macro): {results['val_f1_macro']:.4f}")
        print(f"CV F1 (macro): {results['cv_f1_macro_mean']:.4f} Â± {results['cv_f1_macro_std']:.4f}")
        
        return results
    
    def train_all_models(self, data_splits: Dict[str, np.ndarray]) -> Dict[str, Dict[str, Any]]:
        """å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨æ¯”è¼ƒ"""
        
        X_train = data_splits['X_train']
        y_train = data_splits['y_train']
        X_val = data_splits['X_val']
        y_val = data_splits['y_val']
        
        models_to_train = [
            (self.create_baseline_model(), 'Logistic Regression'),
            (self.create_lightgbm_model(), 'LightGBM'),
            (self.create_catboost_model(), 'CatBoost'),
            (self.create_xgboost_model(), 'XGBoost Enhanced'),
            (self.create_ebm_model(), 'Explainable Boosting Machine'),
            (self.create_random_forest_model(), 'Random Forest'),
            (self.create_ensemble_model(), 'Enhanced Ensemble')
        ]
        
        results = {}
        for model, name in models_to_train:
            try:
                result = self.train_single_model(model, X_train, y_train, X_val, y_val, name)
                results[name] = result
                self.models[name] = model
            except Exception as e:
                print(f"Error training {name}: {str(e)}")
                continue
        
        return results
    
    def select_best_model(self, results: Dict[str, Dict[str, Any]], 
                         metric: str = 'val_f1_macro') -> str:
        """æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ"""
        
        best_score = -1
        best_model_name = None
        
        print(f"\n=== Model Comparison (by {metric}) ===")
        for name, result in results.items():
            score = result[metric]
            print(f"{name}: {score:.4f}")
            
            if score > best_score:
                best_score = score
                best_model_name = name
        
        print(f"\nBest model: {best_model_name} (score: {best_score:.4f})")
        self.best_model = self.models[best_model_name]
        
        return best_model_name
    
    def evaluate_on_test(self, data_splits: Dict[str, np.ndarray], 
                        model_name: Optional[str] = None) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡"""
        
        if model_name is None:
            model = self.best_model
            model_name = "Best Model"
        else:
            model = self.models[model_name]
        
        X_test = data_splits['X_test']
        y_test = data_splits['y_test']
        
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
        
        test_results = {
            'model_name': model_name,
            'test_accuracy': accuracy_score(y_test, y_pred),
            'test_f1_macro': f1_score(y_test, y_pred, average='macro'),
            'test_f1_weighted': f1_score(y_test, y_pred, average='weighted'),
            'classification_report': classification_report(y_test, y_pred),
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'predictions': y_pred,
            'probabilities': y_proba
        }
        
        print(f"\n=== Test Results for {model_name} ===")
        print(f"Test Accuracy: {test_results['test_accuracy']:.4f}")
        print(f"Test F1 (macro): {test_results['test_f1_macro']:.4f}")
        print(f"Test F1 (weighted): {test_results['test_f1_weighted']:.4f}")
        print(f"\nClassification Report:\n{test_results['classification_report']}")
        
        return test_results
    
    def evaluate_repair_requirement_performance(self, data_splits: Dict[str, np.ndarray], 
                                               results: Dict[str, Dict[str, Any]]) -> pd.DataFrame:
        """Repair-requirementã‚¯ãƒ©ã‚¹å°‚ç”¨ã®è©³ç´°è©•ä¾¡"""
        
        X_test = data_splits['X_test']
        y_test = data_splits['y_test']
        
        repair_req_results = []
        
        for model_name, result in results.items():
            model = result['model']
            y_pred = model.predict(X_test)
            
            # Repair-requirement (class 3) ã®æ€§èƒ½ã‚’è©³ç´°åˆ†æ
            repair_req_mask = (y_test == 3)
            repair_req_true = y_test[repair_req_mask]
            repair_req_pred = y_pred[repair_req_mask]
            
            if len(repair_req_true) > 0:
                # Recall (å†ç¾ç‡): Repair-requirementã‚’æ­£ã—ãæ¤œå‡ºã§ããŸå‰²åˆ
                recall = (repair_req_pred == 3).sum() / len(repair_req_true)
                
                # Precision (é©åˆç‡): Repair-requirementã¨äºˆæ¸¬ã—ãŸã‚‚ã®ã®ã†ã¡æ­£è§£ã®å‰²åˆ
                pred_repair_mask = (y_pred == 3)
                if pred_repair_mask.sum() > 0:
                    if hasattr(y_test, 'values'):
                        precision = (y_pred[pred_repair_mask] == y_test.values[pred_repair_mask]).sum() / pred_repair_mask.sum()
                    else:
                        precision = (y_pred[pred_repair_mask] == y_test[pred_repair_mask]).sum() / pred_repair_mask.sum()
                else:
                    precision = 0.0
                
                # F1-score
                if precision + recall > 0:
                    f1 = 2 * (precision * recall) / (precision + recall)
                else:
                    f1 = 0.0
                
                repair_req_results.append({
                    'Model': model_name,
                    'Repair_Req_Recall': recall,
                    'Repair_Req_Precision': precision,
                    'Repair_Req_F1': f1,
                    'Total_Test_Accuracy': result.get('val_accuracy', 0),
                    'Overall_F1_Macro': result.get('val_f1_macro', 0)
                })
        
        repair_df = pd.DataFrame(repair_req_results)
        repair_df = repair_df.sort_values('Repair_Req_F1', ascending=False)
        
        print("\n" + "=" * 60)
        print("ğŸ¯ REPAIR-REQUIREMENT ã‚¯ãƒ©ã‚¹å°‚ç”¨è©•ä¾¡çµæœ")
        print("=" * 60)
        print(repair_df.to_string(index=False, float_format='%.4f'))
        
        # æœ€è‰¯ã®Repair-requirementäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        if not repair_df.empty:
            best_repair_model = repair_df.iloc[0]['Model']
            best_f1 = repair_df.iloc[0]['Repair_Req_F1']
            print(f"\nğŸ† Repair-requirementäºˆæ¸¬æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_repair_model}")
            print(f"   F1-Score: {best_f1:.4f}")
            
            # æ”¹å–„ææ¡ˆ
            if best_f1 < 0.6:
                print("\nğŸ’¡ Repair-requirementäºˆæ¸¬æ”¹å–„ææ¡ˆ:")
                print("   1. ã‚ˆã‚Šå¤šãã®HealthLevel III/IVã‚µãƒ³ãƒ—ãƒ«ã®åé›†")
                print("   2. SMOTEç­‰ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
                print("   3. ã‚³ã‚¹ãƒˆè€ƒæ…®å‹å­¦ç¿’ï¼ˆcost-sensitive learningï¼‰")
                print("   4. é–¾å€¤èª¿æ•´ã«ã‚ˆã‚‹äºˆæ¸¬ãƒãƒ©ãƒ³ã‚¹æœ€é©åŒ–")
        
        return repair_df
    
    def analyze_ebm_interpretability(self, model_name: str = 'Explainable Boosting Machine', 
                                   data_splits: Dict[str, np.ndarray] = None) -> None:
        """EBMãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§åˆ†æ"""
        
        if model_name not in self.models:
            print(f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        model = self.models[model_name]
        
        if not hasattr(model, 'explain_global'):
            print(f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ã¯è§£é‡ˆæ€§æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        try:
            from interpret import show
            
            print(f"\nğŸ” {model_name} è§£é‡ˆæ€§åˆ†æ")
            print("=" * 50)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆï¼ˆå…¨ä½“çš„ãªç‰¹å¾´é‡é‡è¦åº¦ï¼‰
            global_explanation = model.explain_global()
            
            # é‡è¦ãªç‰¹å¾´é‡ã®ã‚µãƒãƒªãƒ¼
            print("é‡è¦ç‰¹å¾´é‡ï¼ˆè§£é‡ˆå¯èƒ½AIçµæœï¼‰:")
            feature_importances = global_explanation.data()
            
            # ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤º
            if hasattr(feature_importances, 'scores') and hasattr(feature_importances, 'names'):
                importance_df = pd.DataFrame({
                    'Feature': feature_importances.names,
                    'Importance': feature_importances.scores
                }).sort_values('Importance', ascending=False).head(10)
                
                print(importance_df.to_string(index=False))
            
            # Repair-requirementäºˆæ¸¬ã«ç‰¹ã«é‡è¦ãªè¦å› ã‚’åˆ†æ
            if data_splits is not None:
                X_test = data_splits['X_test']
                y_test = data_splits['y_test']
                
                # Repair-requirementã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡º
                repair_mask = (y_test == 3)
                if repair_mask.sum() > 0:
                    repair_samples = X_test[repair_mask]
                    
                    print(f"\nğŸ“Š Repair-requirement ã‚µãƒ³ãƒ—ãƒ«åˆ†æ:")
                    print(f"   å¯¾è±¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {repair_samples.shape[0]}")
                    
                    # ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆï¼ˆå€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜ï¼‰ã¯ä¿å­˜ã®ã¿å®Ÿè¡Œ
                    print("   ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆçµæœã¯å†…éƒ¨å‡¦ç†ã§ç”Ÿæˆæ¸ˆã¿")
                    
            print("\nâœ… EBMè§£é‡ˆæ€§åˆ†æå®Œäº†")
            print("   è©³ç´°ãªå¯è¦–åŒ–çµæœã¯ interpret ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§å€‹åˆ¥å®Ÿè¡Œå¯èƒ½")
            
        except ImportError:
            print("interpret ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        except Exception as e:
            print(f"è§£é‡ˆæ€§åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
    
    def plot_confusion_matrix(self, cm: np.ndarray, model_name: str, 
                            class_names: List[str] = None) -> None:
        """æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–"""
        
        plt.figure(figsize=(8, 6))
        
        if class_names is None:
            class_names = [self.reverse_label_mapping.get(i+1, f'Class {i+1}') 
                          for i in range(cm.shape[0])]
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(f'Confusion Matrix - {model_name}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.show()
    
    def get_feature_importance(self, model_name: str = None, top_k: int = 20) -> pd.DataFrame:
        """ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—"""
        
        if model_name is None:
            model = self.best_model
            model_name = "Best Model"
        else:
            model = self.models[model_name]
        
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
        elif hasattr(model, 'coef_'):
            # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®å ´åˆã¯ä¿‚æ•°ã®çµ¶å¯¾å€¤ã®å¹³å‡
            importances = np.abs(model.coef_).mean(axis=0)
        else:
            print(f"Model {model_name} does not support feature importance")
            return pd.DataFrame()
        
        feature_importance_df = pd.DataFrame({
            'feature': self.feature_names if self.feature_names else [f'feature_{i}' for i in range(len(importances))],
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        return feature_importance_df.head(top_k)
    
    def save_model(self, model_name: str = None, filepath: str = None) -> str:
        """ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜"""
        
        if model_name is None:
            model = self.best_model
            model_name = "best_model"
        else:
            model = self.models[model_name]
        
        if filepath is None:
            filepath = f"../models/{model_name.lower().replace(' ', '_')}.joblib"
        
        joblib.dump(model, filepath)
        print(f"Model saved to: {filepath}")
        
        return filepath
    
    def load_model(self, filepath: str) -> Any:
        """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        
        model = joblib.load(filepath)
        print(f"Model loaded from: {filepath}")
        
        return model
    
    def predict(self, X: np.ndarray, model_name: str = None) -> Tuple[np.ndarray, np.ndarray]:
        """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬"""
        
        if model_name is None:
            model = self.best_model
            model_name = "best_model"
        else:
            model = self.models[model_name]
        
        predictions = model.predict(X)
        
        # XGBoostã®å ´åˆã¯äºˆæ¸¬çµæœã‚’å…ƒã®ãƒ©ãƒ™ãƒ«ã«æˆ»ã™
        if 'XGBoost' in model_name or 'xgb' in str(type(model)).lower():
            predictions = predictions + 1
        
        probabilities = None
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(X)
        
        return predictions, probabilities

def main():
    """ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 1000
    n_features = 50
    
    X = np.random.randn(n_samples, n_features)
    y = np.random.randint(1, 4, n_samples)  # HealthLevel 1-3
    
    # åˆ†é¡å™¨ã®åˆæœŸåŒ–
    classifier = HealthLevelClassifier()
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    data_splits = classifier.prepare_data(X, y)
    
    print(f"Training set size: {len(data_splits['X_train'])}")
    print(f"Validation set size: {len(data_splits['X_val'])}")
    print(f"Test set size: {len(data_splits['X_test'])}")
    
    # å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    results = classifier.train_all_models(data_splits)
    
    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
    best_model_name = classifier.select_best_model(results)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
    test_results = classifier.evaluate_on_test(data_splits)
    
    # æ··åŒè¡Œåˆ—ã®è¡¨ç¤º
    classifier.plot_confusion_matrix(
        test_results['confusion_matrix'], 
        best_model_name
    )

if __name__ == "__main__":
    main()