"""
HealthLevelåˆ†é¡MVPã®ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰ç‰¹å¾´é‡ä½œæˆã€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã€è©•ä¾¡ã¾ã§ä¸€é€£ã®å‡¦ç†ã‚’å®Ÿè¡Œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from data_loader import InspectionDataLoader
from feature_engineering import FeatureEngineer
from model_trainer import HealthLevelClassifier

class HealthLevelMVP:
    """HealthLevelåˆ†é¡MVPã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir: str, output_dir: str = "../models"):
        """
        Parameters:
        -----------
        data_dir : str
            ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        output_dir : str
            å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.data_dir = data_dir
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.data_loader = InspectionDataLoader(data_dir)
        self.feature_engineer = FeatureEngineer()
        self.classifier = HealthLevelClassifier()
        
        self.raw_data = None
        self.processed_data = None
        self.aggregated_data = None
        self.features = None
        self.target = None
        self.results = {}
        
    def step1_data_understanding(self):
        """ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ç†è§£ãƒ»åé›†"""
        print("=" * 50)
        print("STEP 1: ãƒ‡ãƒ¼ã‚¿ç†è§£ãƒ»åé›†")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.raw_data = self.data_loader.load_data()
        
        # åŸºæœ¬æƒ…å ±ã®è¡¨ç¤º
        info = self.data_loader.get_basic_info()
        print("\n=== ãƒ‡ãƒ¼ã‚¿åŸºæœ¬æƒ…å ± ===")
        for key, value in info.items():
            print(f"{key}: {value}")
        
        # ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­ã‚’è¡¨ç¤º
        print("\n=== ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« ===")
        print(self.raw_data.head())
        
        # HealthLevelåˆ†å¸ƒã®å¯è¦–åŒ–
        plt.figure(figsize=(10, 6))
        
        plt.subplot(1, 2, 1)
        health_counts = self.raw_data['HealthLevel'].value_counts()
        plt.pie(health_counts.values, labels=health_counts.index, autopct='%1.1f%%')
        plt.title('HealthLevel Distribution')
        
        plt.subplot(1, 2, 2)
        sns.countplot(data=self.raw_data, x='HealthLevel')
        plt.title('HealthLevel Count')
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'health_level_distribution.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return info
    
    def step2_data_preprocessing(self):
        """ã‚¹ãƒ†ãƒƒãƒ—2: å‰å‡¦ç†ï¼ˆRe-Cleansingï¼‰"""
        print("\n" + "=" * 50)
        print("STEP 2: å‰å‡¦ç†ï¼ˆRe-Cleansingï¼‰")
        print("=" * 50)
        
        # åŸºæœ¬å‰å‡¦ç†
        self.processed_data = self.data_loader.basic_preprocessing()
        
        # é›†ç´„ç‰¹å¾´é‡ã®ä½œæˆ
        self.aggregated_data = self.data_loader.create_aggregated_features()
        
        print(f"\nå‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {self.aggregated_data.shape}")
        print(f"é›†ç´„å¾Œã®HealthLevelåˆ†å¸ƒ:")
        print(self.aggregated_data['HealthLevel'].value_counts())
        
        # æ¬ æå€¤ã®ç¢ºèª
        missing_info = self.aggregated_data.isnull().sum()
        print(f"\næ¬ æå€¤æƒ…å ±:")
        print(missing_info[missing_info > 0])
        
        return self.aggregated_data
    
    def step3_data_split(self):
        """ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆSplitï¼‰"""
        print("\n" + "=" * 50)
        print("STEP 3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆSplitï¼‰")
        print("=" * 50)
        
        # HealthLevelã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆIIIä»¥ä¸Šã‚’Repair-requirementã‚¯ãƒ©ã‚¹ã«çµ±åˆï¼‰
        def encode_health_level(level):
            if level == 'â… ':
                return 1
            elif level == 'â…¡':
                return 2
            elif level in ['â…¢', 'â…£', 'â…¤']:
                return 3  # Repair-requirement ã‚¯ãƒ©ã‚¹
            else:
                return None  # Nã‚„ãã®ä»–ã®å€¤ã¯é™¤å¤–
        
        # é›†ç´„ãƒ‡ãƒ¼ã‚¿ã«health_level_encodedãŒãªã„å ´åˆã¯ä½œæˆ
        if 'health_level_encoded' not in self.aggregated_data.columns:
            self.aggregated_data['health_level_encoded'] = self.aggregated_data['HealthLevel'].apply(encode_health_level)
            # Nãƒ¬ãƒ™ãƒ«ã‚’é™¤å¤–
            self.aggregated_data = self.aggregated_data[self.aggregated_data['health_level_encoded'].notna()].copy()
        
        self.aggregated_data['target'] = self.aggregated_data['health_level_encoded']
        
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
        self.target = self.aggregated_data['target'].values
        
        print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ:")
        target_counts = pd.Series(self.target).value_counts().sort_index()
        reverse_mapping = {1: 'â… ', 2: 'â…¡', 3: 'Repair-requirement'}
        for target, count in target_counts.items():
            health_level = reverse_mapping.get(target, f'Unknown-{target}')
            print(f"  {health_level} (Level {target}): {count} samples ({count/len(self.target)*100:.1f}%)")
        
        return self.target
    
    def step4_feature_engineering(self):
        """ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
        print("\n" + "=" * 50)
        print("STEP 4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        print("=" * 50)
        
        # ç‰¹å¾´é‡ã®ä½œæˆ
        self.features, feature_names = self.feature_engineer.create_all_features(
            self.aggregated_data,
            text_columns=['diagnosis_text', 'damage_comment_text'],
            categorical_columns=['BridgeName', 'inspection_year', 'inspection_month'],
            numerical_columns=['diagnosis_count', 'damage_count', 'damage_rank_mean', 
                             'damage_rank_max', 'crack_width_mean', 'crack_width_max', 
                             'area_sum', 'area_max'],
            fit=True
        )
        
        self.classifier.feature_names = feature_names
        
        print(f"ç‰¹å¾´é‡æ•°: {self.features.shape[1]}")
        print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {self.features.shape[0]}")
        print(f"ç‰¹å¾´é‡ã®ç¨®é¡:")
        
        # ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ã®é›†è¨ˆ
        feature_types = {}
        for name in feature_names:
            if name.startswith('tfidf_'):
                feature_types['TF-IDF'] = feature_types.get('TF-IDF', 0) + 1
            elif name.startswith('keyword_'):
                feature_types['Keyword'] = feature_types.get('Keyword', 0) + 1
            elif name.startswith('has_'):
                feature_types['Binary'] = feature_types.get('Binary', 0) + 1
            elif name.startswith('cat_'):
                feature_types['Categorical'] = feature_types.get('Categorical', 0) + 1
            elif name.startswith('num_'):
                feature_types['Numerical'] = feature_types.get('Numerical', 0) + 1
            else:
                feature_types['Other'] = feature_types.get('Other', 0) + 1
        
        for ftype, count in feature_types.items():
            print(f"  {ftype}: {count}")
        
        return self.features, feature_names
    
    def step5_model_building(self):
        """ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼†å­¦ç¿’"""
        print("\n" + "=" * 50)
        print("STEP 5: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼†å­¦ç¿’")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        data_splits = self.classifier.prepare_data(self.features, self.target)
        
        print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(data_splits['X_train'])} samples")
        print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(data_splits['X_val'])} samples")
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(data_splits['X_test'])} samples")
        
        # å…¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        self.results = self.classifier.train_all_models(data_splits)
        
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
        best_model_name = self.classifier.select_best_model(self.results)
        
        return data_splits, best_model_name
    
    def step6_evaluation(self, data_splits, best_model_name):
        """ã‚¹ãƒ†ãƒƒãƒ—6: è©•ä¾¡ï¼ˆEvaluateï¼‰"""
        print("\n" + "=" * 50)
        print("STEP 6: è©•ä¾¡ï¼ˆEvaluateï¼‰")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡
        test_results = self.classifier.evaluate_on_test(data_splits)
        
        # æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
        cm = test_results['confusion_matrix']
        class_names = ['â… ', 'â…¡', 'Repair-requirement'][:cm.shape[0]]
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(f'Confusion Matrix - {best_model_name}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º
        feature_importance = self.classifier.get_feature_importance(top_k=15)
        if not feature_importance.empty:
            plt.figure(figsize=(10, 8))
            sns.barplot(data=feature_importance, y='feature', x='importance')
            plt.title('Feature Importance (Top 15)')
            plt.tight_layout()
            plt.savefig(self.output_dir / 'feature_importance.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("\n=== Top 15 é‡è¦ç‰¹å¾´é‡ ===")
            print(feature_importance.to_string(index=False))
        
        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœã®ä¿å­˜
        comparison_df = pd.DataFrame({
            'Model': [result['model_name'] for result in self.results.values()],
            'Validation Accuracy': [result['val_accuracy'] for result in self.results.values()],
            'Validation F1 (macro)': [result['val_f1_macro'] for result in self.results.values()],
            'CV F1 (macro)': [result['cv_f1_macro_mean'] for result in self.results.values()]
        })
        
        print("\n=== ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ ===")
        print(comparison_df.to_string(index=False))
        
        comparison_df.to_csv(self.output_dir / 'model_comparison.csv', index=False)
        
        # ğŸ¯ Repair-requirementå°‚ç”¨è©•ä¾¡
        repair_performance = self.classifier.evaluate_repair_requirement_performance(data_splits, self.results)
        repair_performance.to_csv(self.output_dir / 'repair_requirement_performance.csv', index=False)
        
        # ğŸ” EBMè§£é‡ˆæ€§åˆ†æ
        self.classifier.analyze_ebm_interpretability('Explainable Boosting Machine', data_splits)
        
        return test_results, feature_importance
    
    def step7_deploy(self, best_model_name):
        """ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ‡ãƒ—ãƒ­ã‚¤ï¼†å¯è¦–åŒ–ï¼ˆUse it!ï¼‰"""
        print("\n" + "=" * 50)
        print("STEP 7: ãƒ‡ãƒ—ãƒ­ã‚¤ï¼†å¯è¦–åŒ–ï¼ˆUse it!ï¼‰")
        print("=" * 50)
        
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        model_path = self.classifier.save_model(best_model_name, 
                                               self.output_dir / f"{best_model_name.lower().replace(' ', '_')}.joblib")
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¿å­˜
        import joblib
        feature_pipeline_path = self.output_dir / "feature_engineer.joblib"
        joblib.dump(self.feature_engineer, feature_pipeline_path)
        print(f"Feature engineering pipeline saved to: {feature_pipeline_path}")
        
        # äºˆæ¸¬é–¢æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ä½œæˆ
        self.create_prediction_script()
        
        print(f"\n=== ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº† ===")
        print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_path}")
        print(f"ç‰¹å¾´é‡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {feature_pipeline_path}")
        print(f"äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: {self.output_dir / 'predict.py'}")
        
        return model_path
    
    def create_prediction_script(self):
        """äºˆæ¸¬ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ"""
        prediction_script = '''"""
HealthLeveläºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ã—ã„æ©‹æ¢è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦HealthLevelã‚’äºˆæ¸¬ã™ã‚‹
"""

import pandas as pd
import numpy as np
import joblib
from pathlib import Path

class HealthLevelPredictor:
    """HealthLeveläºˆæ¸¬å™¨"""
    
    def __init__(self, model_path: str, feature_engineer_path: str):
        """
        Parameters:
        -----------
        model_path : str
            è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        feature_engineer_path : str
            ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‘ã‚¹
        """
        self.model = joblib.load(model_path)
        self.feature_engineer = joblib.load(feature_engineer_path)
        self.label_mapping = {1: 'â… ', 2: 'â…¡', 3: 'Repair-requirement'}
        
    def predict(self, diagnosis_text: str, damage_comment: str = "", 
                bridge_name: str = "Unknown", inspection_date: str = "2024-01-01",
                damage_rank_mean: float = 2.0, damage_count: int = 1) -> dict:
        """
        HealthLevelã‚’äºˆæ¸¬
        
        Parameters:
        -----------
        diagnosis_text : str
            è¨ºæ–­ãƒ†ã‚­ã‚¹ãƒˆ
        damage_comment : str
            æå‚·ã‚³ãƒ¡ãƒ³ãƒˆ
        bridge_name : str
            æ©‹æ¢å
        inspection_date : str
            ç‚¹æ¤œæ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        damage_rank_mean : float
            å¹³å‡æå‚·ãƒ©ãƒ³ã‚¯
        damage_count : int
            æå‚·æ•°
            
        Returns:
        --------
        dict
            äºˆæ¸¬çµæœ
        """
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        input_data = pd.DataFrame({
            'diagnosis_text': [diagnosis_text],
            'damage_comment_text': [damage_comment],
            'BridgeName': [bridge_name],
            'InspectionYMD': [inspection_date],
            'damage_rank_mean': [damage_rank_mean],
            'damage_count': [damage_count],
            'diagnosis_count': [1],
            'damage_rank_max': [damage_rank_mean],
            'crack_width_mean': [np.nan],
            'crack_width_max': [np.nan],
            'area_sum': [np.nan],
            'area_max': [np.nan]
        })
        
        # ç‰¹å¾´é‡ã®ä½œæˆ
        features, _ = self.feature_engineer.create_all_features(
            input_data,
            text_columns=['diagnosis_text', 'damage_comment_text'],
            categorical_columns=['BridgeName', 'inspection_year', 'inspection_month'],
            numerical_columns=['diagnosis_count', 'damage_count', 'damage_rank_mean', 
                             'damage_rank_max', 'crack_width_mean', 'crack_width_max', 
                             'area_sum', 'area_max'],
            fit=False
        )
        
        # äºˆæ¸¬å®Ÿè¡Œ
        prediction = self.model.predict(features)[0]
        probabilities = self.model.predict_proba(features)[0] if hasattr(self.model, 'predict_proba') else None
        
        # çµæœã®æ•´ç†
        result = {
            'predicted_health_level': self.label_mapping[prediction],
            'predicted_health_level_numeric': prediction,
            'confidence': float(probabilities[prediction-1]) if probabilities is not None else None,
            'all_probabilities': {
                self.label_mapping[i+1]: float(prob) 
                for i, prob in enumerate(probabilities)
            } if probabilities is not None else None
        }
        
        return result

def main():
    """äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    # äºˆæ¸¬å™¨ã®åˆæœŸåŒ–
    predictor = HealthLevelPredictor(
        model_path="best_model.joblib",
        feature_engineer_path="feature_engineer.joblib"
    )
    
    # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬
    result = predictor.predict(
        diagnosis_text="ä¸»æ¡ã«é‰„ç­‹éœ²å‡ºãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚é–“è©°ã‚åºŠç‰ˆã«éŠé›¢çŸ³ç°ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚",
        damage_comment="é‰„ç­‹ãŒéœ²å‡ºã—ã¦ãŠã‚Šã€é‰„ç­‹ãŒè…é£Ÿã—ã¦ã„ã‚‹ã€‚",
        bridge_name="å±±ç”°æ©‹",
        inspection_date="2024-03-01",
        damage_rank_mean=3.0,
        damage_count=2
    )
    
    print("=== äºˆæ¸¬çµæœ ===")
    for key, value in result.items():
        print(f"{key}: {value}")

if __name__ == "__main__":
    main()
'''
        
        with open(self.output_dir / 'predict.py', 'w', encoding='utf-8') as f:
            f.write(prediction_script)
    
    def run_full_pipeline(self):
        """å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""
        print("ğŸš€ HealthLevelåˆ†é¡MVP ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        print("=" * 60)
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ç†è§£
            info = self.step1_data_understanding()
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: å‰å‡¦ç†
            processed_data = self.step2_data_preprocessing()
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            target = self.step3_data_split()
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            features, feature_names = self.step4_feature_engineering()
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            data_splits, best_model_name = self.step5_model_building()
            
            # ã‚¹ãƒ†ãƒƒãƒ—6: è©•ä¾¡
            test_results, feature_importance = self.step6_evaluation(data_splits, best_model_name)
            
            # ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ‡ãƒ—ãƒ­ã‚¤
            model_path = self.step7_deploy(best_model_name)
            
            print("\nğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
            print("=" * 60)
            print(f"æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_results['test_accuracy']:.4f}")
            print(f"æœ€çµ‚ãƒ†ã‚¹ãƒˆF1ã‚¹ã‚³ã‚¢: {test_results['test_f1_macro']:.4f}")
            print(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_name}")
            
            return {
                'best_model_name': best_model_name,
                'test_accuracy': test_results['test_accuracy'],
                'test_f1_macro': test_results['test_f1_macro'],
                'model_path': model_path,
                'feature_count': len(feature_names)
            }
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # MVPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
    mvp = HealthLevelMVP(
        data_dir="../1_inspection-dataset",
        output_dir="../models"
    )
    
    results = mvp.run_full_pipeline()
    
    if results:
        print("\nğŸ“Š æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼:")
        for key, value in results.items():
            print(f"  {key}: {value}")

if __name__ == "__main__":
    main()